{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from sklearn import preprocessing\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0        1      2     3     4      5     6     7    8    9   10\n",
      "0   1  1.52101  13.64  4.49  1.10  71.78  0.06  8.75  0.0  0.0   1\n",
      "1   2  1.51761  13.89  3.60  1.36  72.73  0.48  7.83  0.0  0.0   1\n",
      "2   3  1.51618  13.53  3.55  1.54  72.99  0.39  7.78  0.0  0.0   1\n",
      "3   4  1.51766  13.21  3.69  1.29  72.61  0.57  8.22  0.0  0.0   1\n",
      "4   5  1.51742  13.27  3.62  1.24  73.08  0.55  8.07  0.0  0.0   1\n",
      "        1      2     3     4      5     6     7    8    9   10\n",
      "0  1.52101  13.64  4.49  1.10  71.78  0.06  8.75  0.0  0.0   1\n",
      "1  1.51761  13.89  3.60  1.36  72.73  0.48  7.83  0.0  0.0   1\n",
      "2  1.51618  13.53  3.55  1.54  72.99  0.39  7.78  0.0  0.0   1\n",
      "3  1.51766  13.21  3.69  1.29  72.61  0.57  8.22  0.0  0.0   1\n",
      "4  1.51742  13.27  3.62  1.24  73.08  0.55  8.07  0.0  0.0   1\n",
      "[0.4328358208955194, 0.437593984962406, 1.0, 0.25233644859813087, 0.3517857142857146, 0.00966183574879227, 0.30855018587360594, 0.0, 0.0, 0.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "k = 7\n",
    "# data = 'wine_data.csv'\n",
    "data = 'glass.csv'\n",
    "def get_data(data):\n",
    "    X = pd.read_csv(data, sep=\",\", header=None)\n",
    "    print(X.head())\n",
    "    X = X.drop(0, axis=1)\n",
    "    print(X.head())\n",
    "    X_class_col = X[10]\n",
    "#     maxmin_scalar = preprocessing.MinMaxScaler().fit_transform(X)\n",
    "    maxmin_scalar = preprocessing.MinMaxScaler().fit_transform(X.ix[:,:10])\n",
    "#     print(maxmin_scalar)\n",
    "    X = pd.DataFrame(maxmin_scalar)\n",
    "    X = pd.concat([X, X_class_col], axis=1)\n",
    "    X = X.values.tolist()\n",
    "#     print(X.head())\n",
    "    return X\n",
    "X = get_data(data)\n",
    "print(X[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0  1  2\n",
      "0  2  3  4\n",
      "1  4  5  6\n",
      "<type 'numpy.ndarray'>\n",
      "[4 6]\n"
     ]
    }
   ],
   "source": [
    "lst = [[2,3,4], [4,5,6]]\n",
    "np_lst = np.array(lst)\n",
    "print(pd.DataFrame(lst))\n",
    "array = np.mean(lst, axis=0)\n",
    "print(type(array))\n",
    "print(np_lst[:, -1])\n",
    "# Counter(array[0]).most_common(1)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def is_converged(centroids, old_centroids):\n",
    "    return set([tuple(a) for a in centroids]) == set([tuple(b) for b in old_centroids])\n",
    "\n",
    "def get_distance(x, c):\n",
    "    return np.linalg.norm(np.array(x)-np.array(c))\n",
    "\n",
    "def get_clusters(X, centroids):\n",
    "    clusters = defaultdict(list)\n",
    "    for x in X:\n",
    "        # cluster is a num to indicate the # of centroids\n",
    "        cluster = np.argsort([get_distance(x[:-1], c[:-1]) for c in centroids])[0]\n",
    "        clusters[cluster].append(x)\n",
    "    return clusters\n",
    "\n",
    "def get_centeroids(old_centroids, clusters):\n",
    "    new_centroids = []\n",
    "    keys = sorted(clusters.keys())\n",
    "    for k in keys:\n",
    "        new_centroid = np.mean(clusters[k], axis=0)\n",
    "        new_centroid[len(clusters[0][0])-1] = Counter([clusters[k][i][-1] for i in range(len(clusters[k]))]).most_common(1)[0][0]\n",
    "        new_centroids.append(new_centroid)\n",
    "    return new_centroids\n",
    "\n",
    "def find_centers(X, K):\n",
    "    old_centroids = random.sample(X, K)\n",
    "    centroids = random.sample(X, K)\n",
    "    iteration = 0\n",
    "    while not is_converged(centroids, old_centroids):\n",
    "        old_centroids = centroids\n",
    "        clusters = get_clusters(X, centroids)\n",
    "        centroids = get_centeroids(old_centroids, clusters)\n",
    "        iteration += 1\n",
    "    return (centroids, clusters, iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0        1      2     3     4      5     6     7    8    9   10\n",
      "0   1  1.52101  13.64  4.49  1.10  71.78  0.06  8.75  0.0  0.0   1\n",
      "1   2  1.51761  13.89  3.60  1.36  72.73  0.48  7.83  0.0  0.0   1\n",
      "2   3  1.51618  13.53  3.55  1.54  72.99  0.39  7.78  0.0  0.0   1\n",
      "3   4  1.51766  13.21  3.69  1.29  72.61  0.57  8.22  0.0  0.0   1\n",
      "4   5  1.51742  13.27  3.62  1.24  73.08  0.55  8.07  0.0  0.0   1\n",
      "        1      2     3     4      5     6     7    8    9   10\n",
      "0  1.52101  13.64  4.49  1.10  71.78  0.06  8.75  0.0  0.0   1\n",
      "1  1.51761  13.89  3.60  1.36  72.73  0.48  7.83  0.0  0.0   1\n",
      "2  1.51618  13.53  3.55  1.54  72.99  0.39  7.78  0.0  0.0   1\n",
      "3  1.51766  13.21  3.69  1.29  72.61  0.57  8.22  0.0  0.0   1\n",
      "4  1.51742  13.27  3.62  1.24  73.08  0.55  8.07  0.0  0.0   1\n",
      "[array([ 0.30177672,  0.35314602,  0.75553862,  0.31128054,  0.51968985,\n",
      "        0.08394779,  0.30656916,  0.00843776,  0.4375645 ,  0.13157895,  2.        ]), array([  2.53523825e-01,   3.71455913e-01,   7.83721401e-01,\n",
      "         3.71792693e-01,   5.20616883e-01,   9.33684673e-02,\n",
      "         2.62183170e-01,   8.08080808e-04,   2.88770053e-02,\n",
      "         2.03030303e-01,   2.00000000e+00]), array([ 0.29012179,  0.35758627,  0.77654046,  0.30833134,  0.54798535,\n",
      "        0.09025971,  0.28769898,  0.        ,  0.02765209,  0.        ,  1.        ]), array([ 0.57717845,  0.27866541,  0.08741648,  0.3125    ,  0.44620536,\n",
      "        0.04438406,  0.67716078,  0.0625    ,  0.18382353,  0.32291667,  2.        ]), array([ 0.16652034,  0.49273183,  0.67854491,  0.69158879,  0.26904762,\n",
      "        0.26301664,  0.02478315,  0.53121693,  0.        ,  0.88888889,  7.        ]), array([ 0.26891801,  0.53523093,  0.12063846,  0.52521881,  0.56683673,\n",
      "        0.080707  ,  0.32788989,  0.20665155,  0.01820728,  0.91666667,  7.        ]), array([ 0.47752832,  0.47440029,  0.82606851,  0.16941107,  0.33605442,\n",
      "        0.0187869 ,  0.38931669,  0.01209373,  0.04388422,  0.04761905,  1.        ])] 6\n"
     ]
    }
   ],
   "source": [
    "X = get_data(data)\n",
    "num_instances = len(X)\n",
    "centroids, clusters , iteration= find_centers(X, k)\n",
    "print centroids, iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_purity(clusters, centroids, num_instances):\n",
    "    counts = 0\n",
    "    for k in clusters.keys():\n",
    "        labels = np.array(clusters[k])[:, -1]\n",
    "        counts += Counter(labels).most_common(1)[0][1]\n",
    "    return float(counts)/num_instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.742990654206\n"
     ]
    }
   ],
   "source": [
    "purity = get_purity(clusters, centroids, num_instances)\n",
    "print(purity)\n",
    "# for k in clusters.keys():\n",
    "#         points = np.array(clusters[k])\n",
    "#         class_attr = Counter(points[:, -1]).most_common(1)\n",
    "#         print class_attr\n",
    "# print '\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.74"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.95\n",
    "0.74"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
