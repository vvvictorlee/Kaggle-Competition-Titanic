{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('train_processed.csv', dtype=str, usecols=range(1,10))\n",
    "actual = pd.read_csv('gender_submission.csv', usecols=[1], dtype=str)\n",
    "test_data = pd.read_csv('test_processed.csv', usecols=range(1,9), dtype=str)\n",
    "train_X = train_data.drop(['Survived'], axis=1)\n",
    "train_Y = train_data['Survived']\n",
    "test_X = test_data\n",
    "test_Y = actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0    1    2    3    4    5    6    7    8    9  ...    16   17   18   19  \\\n",
      "0 -1.0 -1.0  1.0  1.0 -1.0 -1.0 -1.0  1.0 -1.0 -1.0 ...  -1.0 -1.0 -1.0  1.0   \n",
      "1 -1.0 -1.0  1.0 -1.0  1.0 -1.0 -1.0  1.0 -1.0 -1.0 ...  -1.0 -1.0 -1.0 -1.0   \n",
      "2 -1.0  1.0 -1.0  1.0 -1.0 -1.0 -1.0 -1.0  1.0 -1.0 ...  -1.0 -1.0 -1.0  1.0   \n",
      "3 -1.0 -1.0  1.0  1.0 -1.0 -1.0  1.0 -1.0 -1.0 -1.0 ...  -1.0 -1.0 -1.0 -1.0   \n",
      "4 -1.0 -1.0  1.0 -1.0  1.0 -1.0  1.0 -1.0 -1.0 -1.0 ...  -1.0 -1.0 -1.0 -1.0   \n",
      "\n",
      "    20   21   22   23   24   25  \n",
      "0 -1.0  1.0 -1.0 -1.0 -1.0 -1.0  \n",
      "1  1.0 -1.0 -1.0  1.0 -1.0 -1.0  \n",
      "2 -1.0  1.0 -1.0 -1.0 -1.0 -1.0  \n",
      "3  1.0  1.0 -1.0 -1.0 -1.0 -1.0  \n",
      "4  1.0 -1.0 -1.0  1.0 -1.0 -1.0  \n",
      "\n",
      "[5 rows x 26 columns]\n"
     ]
    }
   ],
   "source": [
    "# one-hot encoding\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder()\n",
    "enc_train_X = enc.fit_transform(train_X)\n",
    "enc_test_X = enc.fit_transform(test_X)\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "min_max_scaler = MinMaxScaler(feature_range=(-1.,1.))\n",
    "enc_train_X = min_max_scaler.fit_transform(enc_train_X.toarray())\n",
    "enc_test_X = min_max_scaler.fit_transform(enc_test_X.toarray())\n",
    "enc_train_X = pd.DataFrame(enc_train_X)\n",
    "enc_test_X = pd.DataFrame(enc_test_X)\n",
    "print(enc_test_X.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make prediction for each row\n",
    "def predict(row, weights, bias):\n",
    "    activation = bias\n",
    "    activation += sum(row*weights)\n",
    "    return 1.0 if activation >= 0.0 else 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train(train_data, n_epoch, learning_rate):\n",
    "#     weights = np.random.rand(train_data.shape[1]-1,1).flatten()\n",
    "    weights = np.random.uniform(-1,1,train_data.shape[1]-1)\n",
    "    bias = 0.5\n",
    "    for epoch in range(n_epoch):\n",
    "        error_sum = 0.0\n",
    "        for row in train_data.values.astype('float'):\n",
    "            pred = predict(row[:-1], weights, bias)\n",
    "#           I wrote it as pred-real; which made it malfunctioning\n",
    "            error = row[-1]-pred\n",
    "            error_sum += error**2\n",
    "            bias += learning_rate*error\n",
    "            weights += learning_rate*error*row[:-1]\n",
    "#         print('>epoch=%d, lrate=%.3f, error=%.3f' % (epoch, learning_rate, error_sum))\n",
    "    return weights, bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def perceptron(train_data, test_X, learning_rate, n_epoch):\n",
    "    predictions = list()\n",
    "    weights, bias = train(train_data, n_epoch, learning_rate)\n",
    "    for row in test_X.values.astype('float'):\n",
    "        prediction = predict(row, weights, bias)\n",
    "        predictions.append(prediction)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def accuracy(actual, predicted):\n",
    "    correct = 0\n",
    "    for i in range(len(actual)):\n",
    "        if actual[i] == predicted[i]:\n",
    "            correct += 1\n",
    "    return correct/float(len(actual))*100.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate(train_data, test_X, test_Y, learning_rate, n_epoch):\n",
    "    predicted = perceptron(train_data, test_X, learning_rate, n_epoch)\n",
    "    acc = accuracy(test_Y, predicted)\n",
    "    print(predicted)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0]\n",
      "The accuracy for SGD is 76.315789\n"
     ]
    }
   ],
   "source": [
    "best_score =0\n",
    "for i in range(1):\n",
    "    train_data = pd.concat([enc_train_X, train_Y], axis=1)\n",
    "    #     print(train_data.head())\n",
    "    test_X = enc_test_X\n",
    "    actual = test_Y.values.astype('float')\n",
    "    learning_rate = 0.01\n",
    "    n_epoch = 100\n",
    "    score = evaluate(train_data, test_X, actual, learning_rate, n_epoch)\n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "print('The accuracy for SGD is %f' % best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.12672268 -0.44328229  0.71540003 -0.00742846 -0.44266876  0.1963046\n",
      " -0.65580191  0.10059205  0.89203522 -0.07477978  0.40331069 -0.42932525\n",
      " -0.81385873 -0.40922669  0.05293893 -0.1468926   0.8055561  -0.60680218\n",
      " -0.76531256 -0.13333172  0.98695769 -0.03569291 -0.36503539 -0.18148858\n",
      " -0.12194093  0.70323212]\n"
     ]
    }
   ],
   "source": [
    "weights = np.random.uniform(-1,1,train_data.shape[1]-1)\n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.76918488, -0.68147978,  0.35146723, -0.34726379, -0.24723325,\n",
       "       -0.32691635, -0.41369798,  0.06263327, -0.92821683, -0.31036156,\n",
       "       -0.8073101 ,  0.66493366,  0.37104266,  0.68949669,  0.48165257,\n",
       "        0.47312651,  0.33912385, -0.71928204,  0.02872441,  0.60868847])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.uniform(-1,1,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([1,2])*np.array([2,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
