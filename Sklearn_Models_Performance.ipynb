{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using scikit models to test againt the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# machine learning\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Load Data (1)-- categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Survived Pclass Sex Age SibSp Parch Fare Embarked Title\n",
       "0        0      3   0   1     1     0    0        2     1\n",
       "1        1      1   1   2     1     0    3        0     3\n",
       "2        1      3   1   1     0     0    1        2     2\n",
       "3        1      1   1   2     1     0    3        2     3\n",
       "4        0      3   0   2     0     0    1        2     1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv('train_processed.csv', dtype=str, usecols=range(1,10))\n",
    "train_X = train_data.drop(['Survived'], axis=1)\n",
    "train_Y = train_data['Survived']\n",
    "test_X = pd.read_csv('test_processed.csv', usecols=range(1,9), dtype=str)\n",
    "test_ID = pd.read_csv('gender_submission.csv')['PassengerId']\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ## Load Data (2)-- one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# one-hot encoding\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder()\n",
    "enc_train_X = enc.fit_transform(train_X)\n",
    "enc_test_X = enc.fit_transform(test_X)\n",
    "enc_train_X = pd.DataFrame(enc_train_X.toarray())\n",
    "enc_test_X = pd.DataFrame(enc_test_X.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applyig a series of ML approaches without Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Classifier  Accuracy(categorical)  Accuracy(onehot)\n",
      "0           MLPClassifier                  76.79             80.03\n",
      "1      LogisticRegression                  79.80             81.27\n",
      "2                     SVC                  81.03             79.34\n",
      "3    KNeighborsClassifier                  78.91             81.37\n",
      "4           MultinomialNB                  76.78             77.56\n",
      "5              Perceptron                  64.10             69.38\n",
      "6           SGDClassifier                  73.94             71.72\n",
      "7  DecisionTreeClassifier                  80.48             79.81\n",
      "8  RandomForestClassifier                  81.49             81.72\n"
     ]
    }
   ],
   "source": [
    "# To Sum up all the tuned models at once\n",
    "# exclude gausssianClassifier because this only accepts dense and it performs awfully\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "classifiers = [\n",
    "    MLPClassifier(),\n",
    "    LogisticRegression(),\n",
    "    SVC(probability=True),\n",
    "    KNeighborsClassifier(n_neighbors=30),\n",
    "    MultinomialNB(),\n",
    "    Perceptron(),\n",
    "    SGDClassifier(),\n",
    "    DecisionTreeClassifier(),\n",
    "    RandomForestClassifier(n_estimators=700)]\n",
    "columns = ['Classifier', 'Accuracy(categorical)', 'Accuracy(onehot)']\n",
    "lists = []\n",
    "datasets = [('cat', train_X, train_Y), ('hot', enc_train_X, train_Y)]\n",
    "acc_dict = {}\n",
    "for cls in classifiers:\n",
    "    name = cls.__class__.__name__\n",
    "    for coding, X, Y in datasets:\n",
    "        scores = cross_val_score(cls, X, Y, cv=10)\n",
    "        acc = round(scores.mean()*100, 2)\n",
    "        acc_dict[coding] = acc\n",
    "    lists.append([name, acc_dict['cat'],acc_dict['hot']])\n",
    "record = pd.DataFrame(lists, columns = columns)\n",
    "print(record)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now, tune each classifier to better accuracy\n",
    "1. Evaluation Method is 10-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# build the final df used for showing all the records\n",
    "columns = ['Classifier', 'Accuracy(categorical)', 'Accuracy(onehot)']\n",
    "lists = []\n",
    "datasets = [('cat', train_X, train_Y), ('hot', enc_train_X, train_Y)]\n",
    "acc_dict = {}\n",
    "name = 'classifierName'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN: find the best K is 17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['KNeighborsClassifier', 81.38, 81.83]]\n",
      "The ideal K should be 22\n"
     ]
    }
   ],
   "source": [
    "# KNN \n",
    "for coding, X, Y in datasets:\n",
    "    res = []\n",
    "    for i in range(1, 50):\n",
    "        cls = KNeighborsClassifier(n_neighbors=i)\n",
    "        name = cls.__class__.__name__\n",
    "        scores = cross_val_score(cls, X, Y, cv=10)\n",
    "        acc_cls = round(scores.mean()*100, 2)\n",
    "        res.append(acc_cls)\n",
    "    acc_dict[coding]=max(res)\n",
    "    best_idx = res.index(acc_dict[coding])+1\n",
    "lists.append([name, acc_dict['cat'], acc_dict['hot']])\n",
    "print(lists)\n",
    "print(\"The ideal K should be %d\" % best_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['KNeighborsClassifier', 81.38, 81.83], ['LogisticRegression', 79.8, 81.27]]\n"
     ]
    }
   ],
   "source": [
    "# LogisticRegression\n",
    "for coding, X, Y in datasets:\n",
    "    cls = LogisticRegression()\n",
    "    name = cls.__class__.__name__\n",
    "    scores = cross_val_score(cls, X, Y, cv=10)\n",
    "    acc_cls = round(scores.mean()*100, 2)\n",
    "    acc_dict[coding] = acc_cls\n",
    "lists.append([name, acc_dict['cat'], acc_dict['hot']])\n",
    "print(lists)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['KNeighborsClassifier', 81.38, 81.83], ['LogisticRegression', 79.8, 81.27], ['SVC', 81.03, 79.34]]\n"
     ]
    }
   ],
   "source": [
    "# SVM \n",
    "for coding, X, Y in datasets:\n",
    "    cls = SVC(probability=True)\n",
    "    name = cls.__class__.__name__\n",
    "    scores = cross_val_score(cls, X, Y, cv=10)\n",
    "    acc_cls = round(scores.mean()*100, 2)\n",
    "    acc_dict[coding] = acc_cls\n",
    "lists.append([name, acc_dict['cat'], acc_dict['hot']])\n",
    "print(lists)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Naive Bayes (dense vectors are required)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['KNeighborsClassifier', 81.38, 81.83], ['LogisticRegression', 79.8, 81.27], ['SVC', 81.03, 79.34], ['GaussianNB', 74.88, '--']]\n"
     ]
    }
   ],
   "source": [
    "# Gaussian Naive Bayes (dense vectors are required)\n",
    "cls = GaussianNB()\n",
    "name = cls.__class__.__name__\n",
    "scores = cross_val_score(cls, train_X, train_Y, cv=10)\n",
    "acc_cls = round(scores.mean()*100, 2)\n",
    "acc_dict['cat'] = acc_cls\n",
    "lists.append([name, acc_dict['cat'], '--'])\n",
    "print(lists)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multinomial Naive Bayes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['KNeighborsClassifier', 81.38, 81.83], ['LogisticRegression', 79.8, 81.27], ['SVC', 81.03, 79.34], ['GaussianNB', 74.88, '--'], ['MultinomialNB', 76.78, 77.56]]\n"
     ]
    }
   ],
   "source": [
    "# Multinomial Naive Bayes (this is comparable with our implemented naive bayers)\n",
    "for coding, X, Y in datasets:\n",
    "    cls = MultinomialNB()\n",
    "    name = cls.__class__.__name__\n",
    "    scores = cross_val_score(cls, X, Y, cv=10)\n",
    "    acc_cls = round(scores.mean()*100, 2)\n",
    "    acc_dict[coding] = acc_cls\n",
    "lists.append([name, acc_dict['cat'], acc_dict['hot']])\n",
    "print(lists)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['KNeighborsClassifier', 81.38, 81.83], ['LogisticRegression', 79.8, 81.27], ['SVC', 81.03, 79.34], ['GaussianNB', 74.88, '--'], ['MultinomialNB', 76.78, 77.56], ['Perceptron', 64.1, 69.38]]\n"
     ]
    }
   ],
   "source": [
    "# Perceptron (not using one hot is better)\n",
    "for coding, X, Y in datasets:\n",
    "    cls = Perceptron()\n",
    "    name = cls.__class__.__name__\n",
    "    scores = cross_val_score(cls, X, Y, cv=10)\n",
    "    acc_cls = round(scores.mean()*100, 2)\n",
    "    acc_dict[coding] = acc_cls\n",
    "lists.append([name, acc_dict['cat'], acc_dict['hot']])\n",
    "print(lists)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['KNeighborsClassifier', 81.38, 81.83], ['LogisticRegression', 79.8, 81.27], ['SVC', 81.03, 79.34], ['GaussianNB', 74.88, '--'], ['MultinomialNB', 76.78, 77.56], ['Perceptron', 64.1, 69.38], ['SGDClassifier', 70.62, 72.83]]\n"
     ]
    }
   ],
   "source": [
    "# Stochastic Gradient Descent (score not stable)\n",
    "for coding, X, Y in datasets:\n",
    "    cls = SGDClassifier()\n",
    "    name = cls.__class__.__name__\n",
    "    scores = cross_val_score(cls, X, Y, cv=10)\n",
    "    acc_cls = round(scores.mean()*100, 2)\n",
    "    acc_dict[coding] = acc_cls\n",
    "lists.append([name, acc_dict['cat'], acc_dict['hot']])\n",
    "print(lists)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['KNeighborsClassifier', 81.38, 81.83], ['LogisticRegression', 79.8, 81.27], ['SVC', 81.03, 79.34], ['GaussianNB', 74.88, '--'], ['MultinomialNB', 76.78, 77.56], ['Perceptron', 64.1, 69.38], ['SGDClassifier', 70.62, 72.83], ['DecisionTreeClassifier', 80.82, 81.04]]\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "alphas = [0.46,0.1,0.2]\n",
    "decisionTreeModel = DecisionTreeClassifier()\n",
    "Grid = GridSearchCV(estimator=decisionTreeModel, param_grid=dict(min_impurity_split=alphas))\n",
    "for coding, X, Y in datasets:\n",
    "    cls = Grid\n",
    "    name = decisionTreeModel.__class__.__name__\n",
    "    scores = cross_val_score(cls, X, Y, cv=10)\n",
    "    acc_cls = round(scores.mean()*100, 2)\n",
    "    acc_dict[coding] = acc_cls\n",
    "lists.append([name, acc_dict['cat'], acc_dict['hot']])\n",
    "print(lists)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest\n",
    "1. feature selection\n",
    "2. tuning using grid search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### feature selecton: abandon useless features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:9: FutureWarning: sort(columns=....) is deprecated, use sort_values(by=.....)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    feature  importance\n",
      "0         0    0.051105\n",
      "1         1    0.035337\n",
      "2         2    0.087180\n",
      "3         3    0.117864\n",
      "4         4    0.133788\n",
      "5         5    0.018265\n",
      "6         6    0.022546\n",
      "7         7    0.024186\n",
      "8         8    0.015837\n",
      "9         9    0.003118\n",
      "10       10    0.019163\n",
      "11       11    0.019156\n",
      "12       12    0.019515\n",
      "13       13    0.018937\n",
      "14       14    0.019730\n",
      "15       15    0.020703\n",
      "16       16    0.025648\n",
      "17       17    0.031344\n",
      "18       18    0.022943\n",
      "19       19    0.014744\n",
      "20       20    0.024382\n",
      "21       21    0.155377\n",
      "22       22    0.034885\n",
      "23       23    0.037883\n",
      "24       24    0.016454\n",
      "25       25    0.009908\n",
      "We original had 26 features for one hot encoding data. Now we only have 24 features.\n",
      "(418, 24)\n"
     ]
    }
   ],
   "source": [
    "# Feature Selection\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "clf = ExtraTreesClassifier(n_estimators=700)\n",
    "clf = clf.fit(enc_train_X, train_Y)\n",
    "features = pd.DataFrame()\n",
    "features['feature'] = enc_train_X.columns\n",
    "features['importance'] = clf.feature_importances_\n",
    "features.sort(['importance'],ascending=False)\n",
    "print(features)\n",
    "# by choosing threshold 0.01, we get rid of two useless features\n",
    "model = SelectFromModel(clf, prefit=True, threshold=0.01)\n",
    "train_new = model.transform(enc_train_X)\n",
    "train_new.shape\n",
    "test_new = model.transform(enc_test_X)\n",
    "print('We original had 26 features for one hot encoding data. Now we only have 24 features.')\n",
    "print(test_new.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tuning RF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.826038159371\n",
      "Best parameters: {'n_estimators': 700, 'criterion': 'entropy', 'max_depth': 5}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.ensemble.gradient_boosting import GradientBoostingClassifier\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "forest = RandomForestClassifier(max_features='sqrt')\n",
    "\n",
    "parameter_grid = {\n",
    "                 'max_depth' : [4,5,6,7,8],\n",
    "                 'n_estimators': [200,450,700],\n",
    "                 'criterion': ['gini','entropy']\n",
    "                 }\n",
    "\n",
    "cross_validation = StratifiedKFold(train_Y, n_folds=10)\n",
    "\n",
    "grid_search = GridSearchCV(forest,\n",
    "                           param_grid=parameter_grid,\n",
    "                           cv=cross_validation)\n",
    "\n",
    "grid_search.fit(train_new, train_Y)\n",
    "\n",
    "print('Best score: {}'.format(grid_search.best_score_))\n",
    "print('Best parameters: {}'.format(grid_search.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['KNeighborsClassifier', 81.38, 81.83], ['LogisticRegression', 79.8, 81.27], ['SVC', 81.03, 79.34], ['GaussianNB', 74.88, '--'], ['MultinomialNB', 76.78, 77.56], ['Perceptron', 64.1, 69.38], ['SGDClassifier', 70.62, 72.83], ['DecisionTreeClassifier', 80.82, 81.04], ['RandomForestClassifier', 80.71, 0.8260381593714927], ['MLPClassifier', 78.58, 80.48], ['RandomForestClassifier', 77.46, 82.6]]\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "cls = RandomForestClassifier(n_estimators = 700)\n",
    "scores = cross_val_score(cls, train_X, train_Y, cv=10)\n",
    "acc_cls = round(scores.mean()*100, 2)\n",
    "acc_dict['cat'] = acc_cls\n",
    "acc_dict['hot'] = round(grid_search.best_score_*100,2)\n",
    "lists.append(['RandomForestClassifier', acc_dict['cat'], acc_dict['hot']])\n",
    "print(lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['KNeighborsClassifier', 81.38, 81.83], ['LogisticRegression', 79.8, 81.27], ['SVC', 81.03, 79.34], ['GaussianNB', 74.88, '--'], ['MultinomialNB', 76.78, 77.56], ['Perceptron', 64.1, 69.38], ['SGDClassifier', 70.62, 72.83], ['DecisionTreeClassifier', 80.82, 81.04], ['RandomForestClassifier', 80.71, 0.8260381593714927], ['MLPClassifier', 78.58, 80.48], ['RandomForestClassifier', 77.46, 82.6], ['MLPClassifier', 77.11, 79.8], ['MLPClassifier', 77.46, 79.8], ['MLPClassifier', 77.67, 79.47], ['MLPClassifier', 77.46, 80.59]]\n"
     ]
    }
   ],
   "source": [
    "# MLP\n",
    "for coding, X, Y in datasets:\n",
    "    cls = MLPClassifier()\n",
    "    name = cls.__class__.__name__\n",
    "    scores = cross_val_score(cls, X, Y, cv=10)\n",
    "    acc_cls = round(scores.mean()*100, 2)\n",
    "    acc_dict[coding] = acc_cls\n",
    "lists.append([name, acc_dict['cat'], acc_dict['hot']])\n",
    "print(lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Classifier  Accuracy(categorical) Accuracy(onehot)\n",
      "0    KNeighborsClassifier                  81.38            81.83\n",
      "1      LogisticRegression                  79.80            81.27\n",
      "2                     SVC                  81.03            79.34\n",
      "3              GaussianNB                  74.88               --\n",
      "4           MultinomialNB                  76.78            77.56\n",
      "5              Perceptron                  64.10            69.38\n",
      "6           SGDClassifier                  70.62            72.83\n",
      "7  DecisionTreeClassifier                  80.82            81.04\n",
      "8  RandomForestClassifier                  80.71         0.826038\n",
      "9           MLPClassifier                  78.58            80.48\n"
     ]
    }
   ],
   "source": [
    "record = pd.DataFrame(lists, columns = columns)\n",
    "print(record)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### The best Model (1) to submit: SVM with categorical dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy on the training set is 0.810346\n",
      "   PassengerId Survived\n",
      "0          892        0\n",
      "1          893        1\n",
      "2          894        0\n",
      "3          895        0\n",
      "4          896        1\n"
     ]
    }
   ],
   "source": [
    "svmModel = SVC(probability=True)\n",
    "svmModel.fit(train_X, train_Y)\n",
    "print('The accuracy on the training set is %f' % cross_val_score(svmModel, train_X, train_Y, cv=10).mean())\n",
    "preds = svmModel.predict(test_X)\n",
    "test_ID = pd.read_csv('gender_submission.csv')\n",
    "submission = pd.DataFrame({\n",
    "        \"PassengerId\": test_ID[\"PassengerId\"],\n",
    "        \"Survived\": preds\n",
    "    })\n",
    "print(submission.head())\n",
    "submission.to_csv('titanic.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### The best Model (2) to submit: RandomForest with one hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy on the training set is 0.826038\n",
      "   PassengerId Survived\n",
      "0          892        0\n",
      "1          893        1\n",
      "2          894        0\n",
      "3          895        0\n",
      "4          896        0\n"
     ]
    }
   ],
   "source": [
    "print('The accuracy on the training set is %f' % grid_search.best_score_)\n",
    "model = grid_search\n",
    "preds = model.predict(test_new)\n",
    "test_ID = pd.read_csv('gender_submission.csv')\n",
    "submission = pd.DataFrame({\n",
    "        \"PassengerId\": test_ID[\"PassengerId\"],\n",
    "        \"Survived\": preds\n",
    "    })\n",
    "print(submission.head())\n",
    "submission.to_csv('titanic.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### The best Model (3) to submit: Logistic Regression with one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy on the training set is 0.812668\n",
      "   PassengerId Survived\n",
      "0          892        0\n",
      "1          893        1\n",
      "2          894        0\n",
      "3          895        0\n",
      "4          896        1\n"
     ]
    }
   ],
   "source": [
    "cls = LogisticRegression()\n",
    "cls.fit(enc_train_X, train_Y)\n",
    "print('The accuracy on the training set is %f' % cross_val_score(cls, enc_train_X, train_Y, cv=10).mean())\n",
    "preds = cls.predict(enc_test_X)\n",
    "test_ID = pd.read_csv('gender_submission.csv')\n",
    "submission = pd.DataFrame({\n",
    "        \"PassengerId\": test_ID[\"PassengerId\"],\n",
    "        \"Survived\": preds\n",
    "    })\n",
    "print(submission.head())\n",
    "submission.to_csv('titanic.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### The best Model (4) to submit: KNN with categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy on the training set is 0.813779\n",
      "   PassengerId Survived\n",
      "0          892        0\n",
      "1          893        1\n",
      "2          894        0\n",
      "3          895        0\n",
      "4          896        1\n"
     ]
    }
   ],
   "source": [
    "cls = KNeighborsClassifier(n_neighbors=20)\n",
    "cls.fit(train_X, train_Y)\n",
    "print('The accuracy on the training set is %f' % cross_val_score(cls, train_X, train_Y, cv=10).mean())\n",
    "preds = cls.predict(test_X)\n",
    "test_ID = pd.read_csv('gender_submission.csv')\n",
    "submission = pd.DataFrame({\n",
    "        \"PassengerId\": test_ID[\"PassengerId\"],\n",
    "        \"Survived\": preds\n",
    "    })\n",
    "print(submission.head())\n",
    "submission.to_csv('titanic.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### The best Model (5) to submit: MLP with categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy on the training set is 0.777948\n",
      "   PassengerId Survived\n",
      "0          892        0\n",
      "1          893        0\n",
      "2          894        0\n",
      "3          895        0\n",
      "4          896        1\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier \n",
    "model = MLPClassifier()\n",
    "model.fit(train_X, train_Y)\n",
    "preds = model.predict(test_X)\n",
    "print('The accuracy on the training set is %f' % cross_val_score(model, train_X, train_Y, cv=10).mean())\n",
    "test_ID = pd.read_csv('gender_submission.csv')\n",
    "submission = pd.DataFrame({\n",
    "        \"PassengerId\": test_ID[\"PassengerId\"],\n",
    "        \"Survived\": preds\n",
    "    })\n",
    "print(submission.head())\n",
    "submission.to_csv('titanic.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
